# ğŸ’» Laptop Price Predictor â€” MLOps Project

> ML-powered laptop price estimation using Random Forest & XGBoost with full MLOps pipeline

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Technologies Used](#technologies-used)
- [Dataset](#dataset)
- [Feature Engineering](#feature-engineering)
- [Models Trained](#models-trained)
- [MLOps Pipeline](#mlops-pipeline)
- [Installation & Setup](#installation--setup)
- [How to Run](#how-to-run)
- [Docker Setup](#docker-setup)
- [CI/CD Pipeline](#cicd-pipeline)
- [Monitoring & Drift Detection](#monitoring--drift-detection)
- [Testing](#testing)
- [Common Errors & Fixes](#common-errors--fixes)
- [Model Performance](#model-performance)
- [File Reference](#file-reference)

---

## ğŸŒŸ Overview

This project predicts laptop prices based on hardware specifications using machine learning. It includes:

- **10 regression models** trained and compared automatically
- **MLflow** experiment tracking for all runs
- **Streamlit** web interface for interactive predictions
- **Docker** containerization for consistent deployment
- **GitHub Actions** CI/CD pipeline for automated training and deployment
- **Drift monitoring** to detect when model needs retraining

---

## ğŸ—ï¸ Architecture

```
flowchart TD
    A[laptop_data.xlsx] -->|pd.read_excel| B[DataLoader]
    B -->|validate schema| C[FeatureEngineer]
    C -->|clean + encode| D[Preprocessed DataFrame]
    D -->|train_test_split| E[ModelTrainer]
    E -->|10 models| F[MLflow Tracking]
    F -->|best RÂ² score| G[best_model.pkl]
    G -->|joblib.load| H[Streamlit App]
    H -->|user input| I[Predict Price]
    I -->|np.exp| J[â‚¹ Price Output]

    G --> K[monitoring/drift_monitor.py]
    K -->|KS Test + ChiÂ²| L[Drift Alerts]
```

**Data Flow Summary:**
1. Excel file loaded â†’ schema validated
2. Raw columns cleaned and features engineered (PPI, CPU brand, GPU brand, etc.)
3. Label encoders fitted and saved alongside model
4. 10 models trained, all logged to MLflow
5. Best model saved as `best_model.pkl`
6. Streamlit app loads model + encoders â†’ serves predictions
7. Every prediction logged for drift monitoring

---

## ğŸ—‚ï¸ Project Structure

```
laptop-price-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ laptop_data.xlsx          â† Source data (1330 rows)
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ preprocessed_data.csv     â† After feature engineering
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_data.py              â† DataLoader class
â”‚   â”‚   â””â”€â”€ preprocess.py             â† FeatureEngineer class
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py                  â† ModelTrainer (all 10 models)
â”‚   â”‚   â””â”€â”€ evaluate.py               â† Metrics + comparison
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ app.py                    â† Streamlit web app
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl                â† Trained best model
â”‚   â”œâ”€â”€ label_encoders.pkl            â† Fitted LabelEncoders
â”‚   â””â”€â”€ feature_cols.pkl              â† Column order used in training
â”‚
â”œâ”€â”€ mlflow/
â”‚   â””â”€â”€ mlruns/
â”‚       â””â”€â”€ mlflow_tracking.py        â† MLflow logging functions
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ drift_monitor.py              â† KS + ChiÂ² drift detection
â”‚   â”œâ”€â”€ reference_data.csv            â† Training data baseline
â”‚   â”œâ”€â”€ drift_logs.json               â† Drift check history
â”‚   â”œâ”€â”€ alerts.json                   â† Model drift alerts
â”‚   â””â”€â”€ prediction_logs.json          â† Per-prediction log
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data.py                  â† Data pipeline unit tests
â”‚   â””â”€â”€ test_models.py                â† Model accuracy unit tests
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb                     â† Exploratory data analysis
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                    â† Container definition
â”‚   â””â”€â”€ docker-compose.yml            â† Multi-service orchestration
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ml_pipeline.yml           â† GitHub Actions CI/CD
â”‚
â”œâ”€â”€ main.py                           â† Training entry point
â”œâ”€â”€ requirements.txt                  â† Python dependencies
â”œâ”€â”€ config.yaml                       â† Hyperparameters config
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technologies Used

| Category | Technology | Purpose |
|---|---|---|
| Language | Python 3.10 | Core language |
| Data | Pandas, NumPy | Data manipulation |
| ML | Scikit-learn | 9 regression models |
| ML | XGBoost | Gradient boosting model |
| MLOps | MLflow | Experiment tracking & model registry |
| Frontend | Streamlit | Interactive web UI |
| Serialization | Joblib | Model save/load |
| Container | Docker | Consistent deployment environment |
| CI/CD | GitHub Actions | Automated training & deployment |
| Testing | Pytest | Unit tests for data + models |
| Package Manager | uv | Fast Python package manager |
| Data Source | OpenPyXL | Excel file reading |

---

## ğŸ“Š Dataset

| Property | Value |
|---|---|
| Source | `laptop_data.xlsx` |
| Rows | 1,330 laptops |
| Target | Price (INR) |
| Features | 10 raw columns |

**Raw Columns:**

| Column | Type | Example |
|---|---|---|
| Company | String | Apple, Dell, HP |
| TypeName | String | Ultrabook, Gaming |
| Inches | Float | 13.3, 15.6 |
| ScreenResolution | String | IPS Panel 2560x1600 |
| Cpu | String | Intel Core i5 2.3GHz |
| Ram | String | 8GB |
| Memory | String | 128GB SSD |
| Gpu | String | Intel Iris Plus 640 |
| OpSys | String | macOS, Windows 10 |
| Weight | String | 1.37kg |
| Price | Float | 71378.68 |

---

## âš™ï¸ Feature Engineering

Raw columns are transformed into 13 model-ready features:

| Feature | Source | Transformation |
|---|---|---|
| Company | Company | LabelEncoder |
| TypeName | TypeName | LabelEncoder |
| Inches | Inches | Direct (float) |
| Ram | Ram (e.g. "8GB") | Extract integer â†’ 8 |
| Weight | Weight (e.g. "1.37kg") | Extract float â†’ 1.37 |
| Touchscreen | ScreenResolution | 1 if "Touchscreen" in string |
| IPS | ScreenResolution | 1 if "IPS" in string |
| ppi | ScreenResolution + Inches | sqrt(xÂ²+yÂ²) / inches |
| Cpu_brand | Cpu | Extract i3/i5/i7/AMD |
| HDD | Memory | Extract HDD GB |
| SSD | Memory | Extract SSD GB |
| Gpu_brand | Gpu | Extract Intel/AMD/Nvidia |
| OpSys | OpSys | LabelEncoder |

**Target transformation:** `log(Price)` â€” log-transform applied for better regression; prediction uses `np.exp()` to reverse.

---

## ğŸ¤– Models Trained

All 10 models below are trained, compared, and logged to MLflow:

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor,
                              AdaBoostRegressor, ExtraTreesRegressor)
from sklearn.svm import SVR
from xgboost import XGBRegressor
```

**Expected Results:**

| Model | Test RÂ² | RMSE |
|---|---|---|
| Random Forest | ~0.86 | ~0.21 |
| XGBoost | ~0.85 | ~0.22 |
| Extra Trees | ~0.85 | ~0.22 |
| Gradient Boosting | ~0.84 | ~0.23 |
| Decision Tree | ~0.78 | ~0.27 |
| AdaBoost | ~0.72 | ~0.31 |
| Ridge | ~0.70 | ~0.32 |
| Linear Regression | ~0.70 | ~0.32 |
| Lasso | ~0.68 | ~0.33 |
| KNeighbors | ~0.67 | ~0.34 |

---

## ğŸ”„ MLOps Pipeline

```
Code Push (GitHub)
        â†“
GitHub Actions triggered
        â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Lint + Test â”‚  â† flake8, black, pytest
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Train Models â”‚  â† main.py runs all 10 models
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ MLflow Tracking â”‚  â† logs metrics, params, artifacts
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Select Best Modelâ”‚  â† highest test RÂ²
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Build Docker Image  â”‚  â† only on main branch
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Push to Docker Hubâ”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Deploy to Cloudâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.10
- `uv` package manager (recommended) or `pip`
- Git

### Install uv (if not installed)

```bash
# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Clone & Setup

```bash
# Clone repository
git clone https://github.com/yourusername/laptop-price-predictor.git
cd laptop-price-predictor

# Create virtual environment
uv venv

# Activate venv
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install all dependencies
uv pip install -r requirements.txt
```

### Verify Installation

```bash
uv run python -c "import numpy; import pandas; import sklearn; import xgboost; print('âœ… All packages OK')"
```

---

## â–¶ï¸ How to Run

### Step 1 â€” Place Dataset

Put `laptop_data.xlsx` inside:
```
data/raw/laptop_data.xlsx
```

### Step 2 â€” Train Model

```bash
uv run python main.py
```

**Expected output:**
```
ğŸ“‚ Loading data...
âœ… Loaded 1330 rows
âš™ï¸  Preprocessing...
ğŸš€ Training Random Forest...
âœ… RÂ² Score: 0.8600
âœ… Features: ['Company', 'TypeName', 'Inches', 'Ram', 'Weight',
              'Touchscreen', 'IPS', 'ppi', 'Cpu_brand', 'HDD',
              'SSD', 'Gpu_brand', 'OpSys']
ğŸ’¾ Models saved to models/
ğŸ‰ Done! Now run: uv run streamlit run src/api/app.py
```

This creates three files in `models/`:
- `best_model.pkl` â€” trained Random Forest
- `label_encoders.pkl` â€” fitted encoders
- `feature_cols.pkl` â€” column order used during training

### Step 3 â€” Run Streamlit App

```bash
uv run streamlit run src/api/app.py
```

Open browser at: **http://localhost:8501**

### Step 4 â€” View MLflow Dashboard (optional)

```bash
mlflow ui --port 5000
```

Open browser at: **http://localhost:5000**

---

## ğŸ³ Docker Setup

### Build & Run Locally

```bash
# Build image
docker build -f docker/Dockerfile -t laptop-price-predictor .

# Run container
docker run -p 8501:8501 laptop-price-predictor
```

### Run with Docker Compose (includes MLflow)

```bash
# Start all services (MLflow + Trainer + API)
docker-compose -f docker/docker-compose.yml up --build

# Services available:
# Streamlit app  â†’ http://localhost:8000
# MLflow UI      â†’ http://localhost:5000

# Stop all services
docker-compose -f docker/docker-compose.yml down
```

### Push to Docker Hub

```bash
# Login
docker login

# Tag image
docker tag laptop-price-predictor yourusername/laptop-price-predictor:latest

# Push
docker push yourusername/laptop-price-predictor:latest
```

### Deploy to Cloud (from Docker Hub image)

```bash
# AWS ECS / Google Cloud Run / Azure Container Apps
# Pull and run from any Linux server:
docker pull yourusername/laptop-price-predictor:latest
docker run -p 8501:8501 yourusername/laptop-price-predictor:latest
```

---

## âš™ï¸ CI/CD Pipeline

The `.github/workflows/ml_pipeline.yml` runs automatically on every push to `main` or `develop`.

**Pipeline stages:**

```
1. lint-and-test
   â”œâ”€â”€ flake8 src/        â† code style check
   â”œâ”€â”€ black --check src/ â† formatting check
   â””â”€â”€ pytest tests/ -v   â† run all unit tests

2. train-models (runs after lint passes)
   â”œâ”€â”€ uv run python main.py
   â””â”€â”€ Upload models/ as artifact

3. docker-build-push (runs on main branch only)
   â”œâ”€â”€ docker build
   â”œâ”€â”€ docker login (uses GitHub Secrets)
   â””â”€â”€ docker push to Docker Hub

4. deploy
   â””â”€â”€ Deploy to cloud provider
```

**Required GitHub Secrets:**
- `DOCKER_USERNAME` â€” your Docker Hub username
- `DOCKER_PASSWORD` â€” your Docker Hub password/token

---

## ğŸ“Š Monitoring & Drift Detection

The `monitoring/drift_monitor.py` module detects when new data has drifted from training data.

### Run Drift Check

```bash
uv run python monitoring/drift_monitor.py
```

### How It Works

**Numeric Features** â†’ Kolmogorov-Smirnov (KS) test
- Checks: Inches, Ram, Weight, ppi, HDD, SSD
- Alert if p-value < 0.05

**Categorical Features** â†’ Chi-Square test
- Checks: Company, TypeName, Cpu_brand, Gpu_brand, OpSys
- Alert if p-value < 0.05

**Model Performance Drift** â†’ RÂ² drop check
- Alert if current RÂ² drops > 0.10 below baseline

**Prediction Logging** â€” every prediction saved to `monitoring/prediction_logs.json`

### Output Example

```
============================================================
ğŸ“Š DATA DRIFT REPORT
   Generated: 2026-02-17T10:30:00
   Reference: 1330 rows | Current: 1330 rows
============================================================

ğŸ”¢ NUMERIC FEATURES:
   Inches          p=0.9200  âœ… OK
   Ram             p=0.8100  âœ… OK
   Weight          p=0.7300  âœ… OK
   ppi             p=0.0200  âš ï¸  DRIFT
   HDD             p=0.6500  âœ… OK
   SSD             p=0.5400  âœ… OK

ğŸ·ï¸  CATEGORICAL FEATURES:
   Company         p=0.9100  âœ… OK

ğŸ“‹ SUMMARY: 1/11 features drifted
âœ… No critical drift detected.
============================================================
```

---

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest tests/ -v

# Run only data tests
uv run pytest tests/test_data.py -v

# Run only model tests
uv run pytest tests/test_models.py -v

# Run with coverage
uv run pytest tests/ --cov=src -v
```

**Test Coverage:**

`test_data.py` â€” 15 tests covering:
- Schema validation (columns, price positivity, no nulls)
- Feature engineering (RAM, weight, CPU, GPU, memory, PPI, resolution)
- Full pipeline (shape, dropped columns, new columns, encoding)

`test_models.py` â€” 9 tests covering:
- All 3 model types produce valid predictions
- RÂ² thresholds (RF > 0.70, XGB > 0.70)
- RF beats Linear Regression
- Model save/load produces identical predictions

---

## ğŸ”§ Common Errors & Fixes

### Error: `numpy.dtype size changed, binary incompatibility`

```bash
# Fix: reinstall compatible versions
uv pip uninstall numpy pandas scikit-learn xgboost -y
uv pip install numpy==1.24.3 pandas==2.0.3 scikit-learn==1.3.0 xgboost==1.7.6
```

### Error: `Model not loaded. Run python main.py first`

```bash
# Fix: train the model first
uv run python main.py
```

### Error: `['Unnamed: 0'] not in index`

Already handled in `main.py` with:
```python
df = pd.read_excel('data/raw/laptop_data.xlsx', index_col=0)
```
And in `preprocess()`:
```python
drop_cols = [c for c in ['Unnamed: 0', 'Cpu', ...] if c in df.columns]
```

### Error: `X has N features, but model expects M features`

Model and app are out of sync. Retrain and restart:
```bash
uv run python main.py
uv run streamlit run src/api/app.py
```

### Error: `os is not defined` in app.py

Add `import os` at the top of `app.py`.

### Streamlit uses wrong Python (package not found)

```bash
# Always use uv run prefix
uv run streamlit run src/api/app.py

# Verify which Python uv uses
uv run python -c "import sys; print(sys.executable)"
```

---

## ğŸ“ˆ Model Performance

| Metric | Value |
|---|---|
| Best Model | Random Forest Regressor |
| Test RÂ² | ~0.86 |
| RMSE | ~0.21 |
| MAE | ~0.15 |
| Training Samples | 1,064 (80%) |
| Test Samples | 266 (20%) |
| Target Transform | log(Price) |
| Features Used | 13 engineered features |

---

## ğŸ“ File Reference

| File | Description |
|---|---|
| `main.py` | Entry point: loads data, preprocesses, trains, saves model |
| `src/api/app.py` | Streamlit UI with sidebar inputs and prediction display |
| `src/data/load_data.py` | DataLoader class with schema validation |
| `src/data/preprocess.py` | FeatureEngineer class with all transformations |
| `src/models/train.py` | ModelTrainer class for all 10 models with MLflow |
| `src/models/evaluate.py` | Model evaluation and comparison utilities |
| `mlflow/mlruns/mlflow_tracking.py` | MLflow logging helpers |
| `monitoring/drift_monitor.py` | KS + ChiÂ² drift detection + prediction logging |
| `tests/test_data.py` | 15 unit tests for data pipeline |
| `tests/test_models.py` | 9 unit tests for model training and persistence |
| `docker/Dockerfile` | Container definition for deployment |
| `docker/docker-compose.yml` | MLflow + Trainer + API orchestration |
| `.github/workflows/ml_pipeline.yml` | CI/CD: lint â†’ train â†’ docker â†’ deploy |
| `models/best_model.pkl` | Saved best model (generated by main.py) |
| `models/label_encoders.pkl` | Saved LabelEncoders (generated by main.py) |
| `models/feature_cols.pkl` | Column order used in training (generated by main.py) |

---

## ğŸ¤ Contributing

Pull requests welcome. For major changes, open an issue first.

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¤ Author

**Saikiranabhi**
GitHub: [https://github.com/Saikiranabhi/laptop-price-predictor](https://github.com/Saikiranabhi/laptop-price-predictor)
